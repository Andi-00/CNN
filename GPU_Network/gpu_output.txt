Tue Aug 22 09:51:37 CEST 2023
[INFO] Module zlib/1.2.12 loaded.
[INFO] Module binutils/2.38 loaded.
[INFO] Module numactl/2.0.14 loaded.
[INFO] Module GCCcore/.9.3.0 loaded.
[INFO] Module zlib/1.2.12 loaded.
[INFO] Module binutils/2.38 loaded.

Inactive Modules:
  1) UCX/1.12.1

Due to MODULEPATH changes, the following have been reloaded:
  1) binutils/2.38     2) numactl/2.0.14     3) zlib/1.2.12

The following have been reloaded with a version change:
  1) GCCcore/.11.3.0 => GCCcore/.9.3.0

[INFO] Module Python/3.9.6 loaded.

The following have been reloaded with a version change:
  1) binutils/2.38 => binutils/2.37     2) zlib/1.2.12 => zlib/1.2.11

[INFO] Module cuDNN/8.1.1.33-CUDA-11.2.1 loaded.
Tue Aug 22 09:51:37 CEST 2023
start loading data
(2400, 79, 2001, 1)
end loading data
Dauer : 10:08 (min:sec)
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 77, 1999, 16)      160       
                                                                 
 conv2d_1 (Conv2D)           (None, 75, 1997, 16)      2320      
                                                                 
 max_pooling2d (MaxPooling2D  (None, 37, 998, 16)      0         
 )                                                               
                                                                 
 conv2d_2 (Conv2D)           (None, 35, 996, 32)       4640      
                                                                 
 conv2d_3 (Conv2D)           (None, 33, 994, 32)       9248      
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 16, 497, 32)      0         
 2D)                                                             
                                                                 
 conv2d_4 (Conv2D)           (None, 14, 495, 64)       18496     
                                                                 
 conv2d_5 (Conv2D)           (None, 12, 493, 64)       36928     
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 6, 246, 64)       0         
 2D)                                                             
                                                                 
 conv2d_6 (Conv2D)           (None, 4, 244, 128)       73856     
                                                                 
 conv2d_7 (Conv2D)           (None, 2, 242, 128)       147584    
                                                                 
 max_pooling2d_3 (MaxPooling  (None, 1, 121, 128)      0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 15488)             0         
                                                                 
 dense (Dense)               (None, 128)               1982592   
                                                                 
 dense_1 (Dense)             (None, 128)               16512     
                                                                 
 dense_2 (Dense)             (None, 5)                 645       
                                                                 
=================================================================
Total params: 2,292,981
Trainable params: 2,292,981
Non-trainable params: 0
_________________________________________________________________
Epoch 1/40
75/75 - 10s - loss: 0.1427 - custom_loss: 1.3544 - val_loss: 0.1300 - val_custom_loss: 0.4608 - 10s/epoch - 136ms/step
Epoch 2/40
75/75 - 4s - loss: 0.1266 - custom_loss: 1.3020 - val_loss: 0.1210 - val_custom_loss: 0.4778 - 4s/epoch - 55ms/step
Epoch 3/40
75/75 - 4s - loss: 0.1181 - custom_loss: 1.2272 - val_loss: 0.1202 - val_custom_loss: 0.4099 - 4s/epoch - 55ms/step
Epoch 4/40
75/75 - 4s - loss: 0.1140 - custom_loss: 1.2644 - val_loss: 0.1122 - val_custom_loss: 0.4253 - 4s/epoch - 55ms/step
Epoch 5/40
75/75 - 4s - loss: 0.1099 - custom_loss: 1.1373 - val_loss: 0.1113 - val_custom_loss: 0.4087 - 4s/epoch - 55ms/step
Epoch 6/40
75/75 - 4s - loss: 0.1073 - custom_loss: 1.1557 - val_loss: 0.1127 - val_custom_loss: 0.4689 - 4s/epoch - 55ms/step
Epoch 7/40
75/75 - 4s - loss: 0.1059 - custom_loss: 1.1203 - val_loss: 0.1060 - val_custom_loss: 0.4288 - 4s/epoch - 55ms/step
Epoch 8/40
75/75 - 4s - loss: 0.1023 - custom_loss: 0.9477 - val_loss: 0.1112 - val_custom_loss: 0.3980 - 4s/epoch - 55ms/step
Epoch 9/40
75/75 - 4s - loss: 0.1020 - custom_loss: 1.0227 - val_loss: 0.1083 - val_custom_loss: 0.4099 - 4s/epoch - 55ms/step
Epoch 10/40
75/75 - 4s - loss: 0.0509 - custom_loss: 0.7932 - val_loss: 0.0381 - val_custom_loss: 0.3789 - 4s/epoch - 55ms/step
Epoch 11/40
75/75 - 4s - loss: 0.0324 - custom_loss: 0.7303 - val_loss: 0.0422 - val_custom_loss: 0.4157 - 4s/epoch - 55ms/step
Epoch 12/40
75/75 - 4s - loss: 0.0295 - custom_loss: 0.7110 - val_loss: 0.0423 - val_custom_loss: 0.3913 - 4s/epoch - 55ms/step
Epoch 13/40
75/75 - 4s - loss: 0.0280 - custom_loss: 0.5274 - val_loss: 0.0430 - val_custom_loss: 0.3634 - 4s/epoch - 55ms/step
Epoch 14/40
75/75 - 4s - loss: 0.0256 - custom_loss: 0.5039 - val_loss: 0.0413 - val_custom_loss: 0.3826 - 4s/epoch - 55ms/step
Epoch 15/40
75/75 - 4s - loss: 0.0238 - custom_loss: 0.4278 - val_loss: 0.0423 - val_custom_loss: 0.3958 - 4s/epoch - 55ms/step
Epoch 16/40
75/75 - 4s - loss: 0.0216 - custom_loss: 0.4389 - val_loss: 0.0464 - val_custom_loss: 0.4301 - 4s/epoch - 55ms/step
Epoch 17/40
75/75 - 4s - loss: 0.0196 - custom_loss: 0.4023 - val_loss: 0.0447 - val_custom_loss: 0.4098 - 4s/epoch - 55ms/step
Epoch 18/40
75/75 - 4s - loss: 0.0189 - custom_loss: 0.3423 - val_loss: 0.0477 - val_custom_loss: 0.4191 - 4s/epoch - 55ms/step
Epoch 19/40
75/75 - 4s - loss: 0.0170 - custom_loss: 0.4229 - val_loss: 0.0472 - val_custom_loss: 0.4139 - 4s/epoch - 55ms/step
Epoch 20/40
75/75 - 4s - loss: 0.0141 - custom_loss: 0.3000 - val_loss: 0.0484 - val_custom_loss: 0.3786 - 4s/epoch - 55ms/step
Epoch 21/40
75/75 - 4s - loss: 0.0122 - custom_loss: 0.2287 - val_loss: 0.0460 - val_custom_loss: 0.3749 - 4s/epoch - 55ms/step
Epoch 22/40
75/75 - 4s - loss: 0.0106 - custom_loss: 0.1928 - val_loss: 0.0502 - val_custom_loss: 0.3843 - 4s/epoch - 55ms/step
Epoch 23/40
75/75 - 4s - loss: 0.0092 - custom_loss: 0.2062 - val_loss: 0.0529 - val_custom_loss: 0.3731 - 4s/epoch - 55ms/step
Epoch 24/40
75/75 - 4s - loss: 0.0078 - custom_loss: 0.2020 - val_loss: 0.0496 - val_custom_loss: 0.4001 - 4s/epoch - 55ms/step
Epoch 25/40
75/75 - 4s - loss: 0.0070 - custom_loss: 0.1423 - val_loss: 0.0512 - val_custom_loss: 0.4001 - 4s/epoch - 55ms/step
Epoch 26/40
75/75 - 4s - loss: 0.0062 - custom_loss: 0.1304 - val_loss: 0.0509 - val_custom_loss: 0.3658 - 4s/epoch - 55ms/step
Epoch 27/40
75/75 - 4s - loss: 0.0055 - custom_loss: 0.1126 - val_loss: 0.0521 - val_custom_loss: 0.3908 - 4s/epoch - 55ms/step
Epoch 28/40
75/75 - 4s - loss: 0.0045 - custom_loss: 0.1038 - val_loss: 0.0497 - val_custom_loss: 0.3738 - 4s/epoch - 55ms/step
Epoch 29/40
75/75 - 4s - loss: 0.0040 - custom_loss: 0.0861 - val_loss: 0.0524 - val_custom_loss: 0.3841 - 4s/epoch - 55ms/step
Epoch 30/40
75/75 - 4s - loss: 0.0036 - custom_loss: 0.0848 - val_loss: 0.0482 - val_custom_loss: 0.3896 - 4s/epoch - 55ms/step
Epoch 31/40
75/75 - 4s - loss: 0.0032 - custom_loss: 0.0742 - val_loss: 0.0512 - val_custom_loss: 0.3646 - 4s/epoch - 55ms/step
Epoch 32/40
75/75 - 4s - loss: 0.0029 - custom_loss: 0.0749 - val_loss: 0.0485 - val_custom_loss: 0.3845 - 4s/epoch - 55ms/step
Epoch 33/40
75/75 - 4s - loss: 0.0029 - custom_loss: 0.0810 - val_loss: 0.0504 - val_custom_loss: 0.3774 - 4s/epoch - 55ms/step
Epoch 34/40
75/75 - 4s - loss: 0.0028 - custom_loss: 0.0745 - val_loss: 0.0527 - val_custom_loss: 0.3823 - 4s/epoch - 55ms/step
Epoch 35/40
75/75 - 4s - loss: 0.0029 - custom_loss: 0.0725 - val_loss: 0.0513 - val_custom_loss: 0.4023 - 4s/epoch - 55ms/step
Epoch 36/40
75/75 - 4s - loss: 0.0034 - custom_loss: 0.0808 - val_loss: 0.0514 - val_custom_loss: 0.4038 - 4s/epoch - 55ms/step
Epoch 37/40
75/75 - 4s - loss: 0.0033 - custom_loss: 0.1436 - val_loss: 0.0501 - val_custom_loss: 0.3751 - 4s/epoch - 55ms/step
Epoch 38/40
75/75 - 4s - loss: 0.0030 - custom_loss: 0.0748 - val_loss: 0.0500 - val_custom_loss: 0.3679 - 4s/epoch - 55ms/step
Epoch 39/40
75/75 - 4s - loss: 0.0034 - custom_loss: 0.0813 - val_loss: 0.0492 - val_custom_loss: 0.3711 - 4s/epoch - 55ms/step
Epoch 40/40
75/75 - 4s - loss: 0.0029 - custom_loss: 0.0686 - val_loss: 0.0503 - val_custom_loss: 0.3928 - 4s/epoch - 55ms/step
 1/10 [==>...........................] - ETA: 0s - loss: 0.0493 - custom_loss: 0.5305 4/10 [===========>..................] - ETA: 0s - loss: 0.0532 - custom_loss: 1.0086 7/10 [====================>.........] - ETA: 0s - loss: 0.0495 - custom_loss: 0.722410/10 [==============================] - 0s 19ms/step - loss: 0.0518 - custom_loss: 0.7690
[0.051837217062711716, 0.7690301537513733]
Traceback (most recent call last):
  File "/rwthfs/rz/cluster/home/cg457676/EMRI_waveform/CNN/GPU_Network/./network.py", line 129, in <module>
    np.save("./gpu_history.npy")
TypeError: save() missing 1 required positional argument: 'arr'
Tue Aug 22 10:05:16 CEST 2023
